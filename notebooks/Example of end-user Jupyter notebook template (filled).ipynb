{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d6d907",
   "metadata": {},
   "source": [
    "# Federating centralized machine learning in a private Jupyter notebook to distributed institutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c2398",
   "metadata": {},
   "source": [
    "User input (AI researcher module): in this notebook, AI developers can customize the way the data will be load as well as the model architecture that will be used to train models at each collaborating institution within the federation. This implementation, preferably in [PyTorch](https://pytorch.org/) for this first version, will then be integrated in the [Flower](https://flower.dev/) application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c224399f",
   "metadata": {},
   "source": [
    "<img src=\"../figures/federation_figure.JPG\" alt=\"Overview\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8947d2",
   "metadata": {},
   "source": [
    "## How to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4327584",
   "metadata": {},
   "source": [
    "In this notebook, the overall structure of the code has been pre-filled so that the user only has to complete the missing parts.<br/>Note that all comments (preceded by a \"#\" sign) correspond to parts of code that need completion. Comments in quotation marks indicate the specific inputs and/or outputs that are needed for a given function or class to be further successfully integrated into the [Flower](https://flower.dev/) application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc3916a",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d343e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# import ...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e8ee92",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e51d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(df_data, dir_data, input_shape):\n",
    "    \"\"\"Function to load images to study and apply preprocessing if needed.\"\"\"\n",
    "    list_images = []\n",
    "    dir_data = dir_data + \"/patches/\"\n",
    "    print(\"dir_data: \", dir_data)\n",
    "    for i in range(0, len(df_data)):\n",
    "        img = cv2.imread(dir_data + df_data.images[i])\n",
    "        img = cv2.resize(img, input_shape)\n",
    "        list_images.append(img)\n",
    "\n",
    "    return np.array(list_images)\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, partition_file, folder, input_shape):\n",
    "        ### START CODE HERE ###\n",
    "        self.input_shape = input_shape\n",
    "        \n",
    "        df_data = pd.read_csv(folder + \"/\" + partition_file + '.csv', dtype=str, delimiter=',')\n",
    "        val_counts = df_data['GT'].value_counts()\n",
    "        factor = 1-(val_counts[1]/val_counts[0])\n",
    "        # Balance dataset\n",
    "        df_data = df_data.drop(df_data.loc[df_data['GT']=='0'].sample(frac=float(factor)).index).reset_index()\n",
    "        # Load images for the experiment and their corresponding labels\n",
    "        self.X = load_images(df_data, folder, self.input_shape)\n",
    "        self.Y = df_data.GT\n",
    "        self.Y = [int(el) for el in self.Y]\n",
    "        \n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        self.indexes = np.arange(0, len(self.X))\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Required output: length of the dataset\"\"\"\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Required input: index to access\n",
    "        Required output: image corresponding to the input index and its label\"\"\"\n",
    "        \n",
    "        image = self.X[idx]\n",
    "        label = self.Y[idx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3285907",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd89fcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path, input_shape=(224,224)):\n",
    "    \"\"\"Load data (training, validation and test sets).\n",
    "    Required outputs: loaders of each set and dictionary containing the length of each corresponding set\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    trainset = CustomDataset(partition_file=\"train_client\", folder=data_path, input_shape=input_shape)\n",
    "    valset = CustomDataset(partition_file=\"val_client\", folder=data_path, input_shape=input_shape)\n",
    "    testset = CustomDataset(partition_file=\"test\", folder=data_path, input_shape=input_shape)\n",
    "    \n",
    "    trainloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    valloader = DataLoader(valset, batch_size=64, shuffle=True)\n",
    "    testloader = DataLoader(testset, batch_size=64, shuffle=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    num_examples = {\"trainset\" : len(trainset), \"valset\": len(valset), \"testset\" : len(testset)}\n",
    "    \n",
    "    return trainloader, valloader, testloader, num_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e761d12",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3493cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \"\"\"Model architecture. Inputs in the init function can be added if needed.\"\"\"\n",
    "    def __init__(self, input_shape=(224,224), n_classes=2):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        ### START CODE HERE ###\n",
    "        self.input_shape = input_shape\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        # Define model architecture\n",
    "        self.model = models.vgg16(pretrained=False)\n",
    "        self.model.classifier[-1] = torch.nn.Linear(in_features=4096, out_features=self.n_classes)\n",
    "\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Required input: tensor of images to predict\n",
    "        Required output: output of the model given the images tensor in input\"\"\"\n",
    "            \n",
    "        ### START CODE HERE ###\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        x = self.model(x)\n",
    "        x = torch.squeeze(x)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e503eb55",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ad2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainloader, valloader, epochs):\n",
    "    \"\"\"Train the network on the training set, evaluating it on the validation set at each epoch.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss() #TODO Define loss function\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001) #TODO Define optimizer\n",
    "    \n",
    "    start = time.time()\n",
    "    for i_epoch in range(epochs):\n",
    "        ### START CODE HERE ###\n",
    "        print(\"Epoch \", i_epoch+1)\n",
    "        \n",
    "        correct, total, train_loss_epoch = 0, 0, 0.0\n",
    "        for images, labels in trainloader:\n",
    "            images = torch.from_numpy(np.asarray(images).astype('float32'))\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            loss_iteration = criterion(outputs, labels)\n",
    "            loss_iteration.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            train_loss_epoch += loss_iteration.item()\n",
    "        \n",
    "        train_loss_epoch = train_loss_epoch / total\n",
    "        train_acc_epoch = correct / total\n",
    "        val_loss_epoch, val_acc_epoch = test(net, valloader)\n",
    "        info = \"[INFO] Epoch {}/{} - train_loss: {:.6f} - train_acc: {:.6f} - val_loss: {:.6f} - val_acc: {:.6f}\".format(\n",
    "                i_epoch + 1, epochs, train_loss_epoch, train_acc_epoch, val_loss_epoch, val_acc_epoch)\n",
    "        print(info + \"\\n\")\n",
    "        \n",
    "    end = time.time()\n",
    "    print(\"Time to train the whole network: \", end-start, \" s\")\n",
    "        \n",
    "        ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4842df92",
   "metadata": {},
   "source": [
    "## Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d28ecfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
    "    criterion = torch.nn.CrossEntropyLoss() #TODO Define loss function\n",
    "    \n",
    "    correct, total, loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        ### START CODE HERE ###\n",
    "        for data in testloader:\n",
    "            images = torch.from_numpy(np.asarray(data[0]).astype('float32'))\n",
    "            images, labels = images.to(DEVICE), data[1].to(DEVICE)\n",
    "            outputs = net(images)\n",
    "            loss += criterion(outputs, labels).item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = correct / total\n",
    "    loss = loss / total\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88baf3",
   "metadata": {},
   "source": [
    "## Aggregation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aeb383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://flower.dev/docs/implementing-strategies.html\n",
    "\n",
    "strategy = fl.server.strategy.FedAvg(\n",
    "    # ... other FedAvg arguments\n",
    "    fraction_fit=1,\n",
    "    fraction_eval=1,\n",
    "    min_fit_clients=3,\n",
    "    min_available_clients=2,\n",
    ")\n",
    "\n",
    "config = {\"num_rounds\": 3}\n",
    "grpc_max_message_length = 895_870_912"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
